
# Fine-Tuning de Mistral-7B para Consultas sobre *Drácula*  

Este repositorio contiene el proyecto de desarrollo de un modelo de **fine-tuning** basado en **mistralai/Mistral-7B-Instruct-v0.2**, diseñado específicamente para responder de manera efectiva a consultas relacionadas con *Drácula*, la obra clásica de Bram Stoker publicada en 1897.

---

## Objetivo del Proyecto  

Crear un modelo optimizado para responder preguntas sobre *Drácula*, utilizando técnicas de procesamiento de lenguaje natural y herramientas de aprendizaje profundo.  

---

## Proceso de Desarrollo  

### 1. Preparación de Datos  
- **Fuente del texto:**  
  Se utilizó una versión de dominio público del libro en formato **TXT**.  

- **Generación de datos de entrenamiento:**  
  - El libro fue dividido en fragmentos de 1000 palabras.  
  - A partir de estos fragmentos, se generaron **1132 preguntas y respuestas** utilizando otro modelo de lenguaje.  
  - Esto resultó en la creación de **dos datasets**:  
    1. Un dataset con todas las preguntas generadas.  
    2. Un dataset filtrado mediante un proceso de **ETL** para optimizar los datos.  

---

### 2. Entrenamiento del Modelo  
- **Infraestructura utilizada:**  
  - El entrenamiento se realizó de forma local, empleando **Docker** y **Google Colab**, utilizando una tarjeta gráfica **RTX 3060**.  

- **Técnicas de entrenamiento:**  
  - Se utilizó la configuración de **QLoRA** para reducir el consumo de recursos.  
  - El modelo fue cuantizado y posteriormente almacenado en **Hugging Face** para su distribución.  

- **Enlace al modelo:**  
  [Ver modelo en Hugging Face](https://huggingface.co/cramirezg/Mistral-7B-Instruct-v0.2-autogenerated-Spanish-DraculaBramStoker-GGUF)  

## Licencia  

Este proyecto utiliza una versión de dominio público de *Drácula* de bram stoker del año 1897.